import pandas as pd
import numpy as np
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')

# Project paths
PROJECT_ROOT = Path(__file__).resolve().parent.parent
RAW_DATA_PATH = PROJECT_ROOT / "data" / "raw" / "train.csv"
PROCESSED_DATA_PATH = PROJECT_ROOT / "data" / "processed" / "train_features.csv"

def extract_time_features(df):
    """Extract temporal features from date column."""
    logging.info("Extracting time-based features...")
    df['date'] = pd.to_datetime(df['date'])
    df['day_of_week'] = df['date'].dt.dayofweek
    df['day_of_month'] = df['date'].dt.day
    df['month'] = df['date'].dt.month
    df['year'] = df['date'].dt.year
    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
    return df

def create_lag_features(df, lags=[1, 7, 30, 90, 365]):
    """Create lag features over different periods to capture auto-correlation."""
    logging.info(f"Generating lag features for lags {lags}...")
    # Sort carefully to ensure sequence ordering matters per store/item
    df = df.sort_values(by=['store', 'item', 'date'])
    for lag in lags:
        df[f'sales_lag_{lag}'] = df.groupby(['store', 'item'])['sales'].shift(lag)
    return df

def create_rolling_features(df, windows=[7, 30]):
    """Create rolling mean and std features."""
    logging.info(f"Generating rolling features for windows {windows}...")
    df = df.sort_values(by=['store', 'item', 'date'])
    for w in windows:
        df[f'sales_roll_mean_{w}'] = df.groupby(['store', 'item'])['sales'].transform(lambda x: x.rolling(window=w, min_periods=1).mean())
        df[f'sales_roll_std_{w}'] = df.groupby(['store', 'item'])['sales'].transform(lambda x: x.rolling(window=w, min_periods=1).std())
    return df

def clean_data(df):
    """Handle missing values generated by lag/rolling operations."""
    logging.info("Cleaning missing values and anomalies...")
    # For features that resulted in NaNs due to shift/rolling operations at the start of series, 
    # we can either drop those rows or impute. We'll drop rows before the first lag (1 year),
    # or just fill backward if we want to keep maximum data. Due to Kaggle constraints (900k rows),
    # dropping the first year (out of 5) is acceptable for sequence forecasting, but we'll 
    # bfill lag features to retain data for simplicity.
    df = df.bfill()
    df.fillna(0, inplace=True) # Catch-all for residual std == NaN on size 1 windows
    return df

def main():
    if not RAW_DATA_PATH.exists():
        logging.error(f"Raw data file {RAW_DATA_PATH} not found. Please run data_ingestion.py first.")
        return

    logging.info(f"Loading raw dataset from {RAW_DATA_PATH}...")
    df = pd.read_csv(RAW_DATA_PATH)
    logging.info(f"Loaded {len(df)} rows.")

    df = extract_time_features(df)
    df = create_lag_features(df)
    df = create_rolling_features(df)
    df = clean_data(df)

    logging.info(f"Saving processed features to {PROCESSED_DATA_PATH}...")
    PROCESSED_DATA_PATH.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(PROCESSED_DATA_PATH, index=False)
    logging.info("Preprocessing completed successfully.")

if __name__ == "__main__":
    main()
