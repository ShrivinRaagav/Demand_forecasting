import pandas as pd
import numpy as np
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')

# Project paths
PROJECT_ROOT = Path(__file__).resolve().parent.parent
RAW_DATA_PATH = PROJECT_ROOT / "data" / "raw" / "powergrid_demand_data.csv"
PROCESSED_DATA_PATH = PROJECT_ROOT / "data" / "processed" / "powergrid_features.csv"

def extract_time_features(df):
    """Extract temporal features from date column mapped to construction cycles."""
    logging.info("Extracting supply chain time-based features...")
    df['date'] = pd.to_datetime(df['date'])
    df['week_of_year'] = df['date'].dt.isocalendar().week
    df['month'] = df['date'].dt.month
    df['quarter'] = df['date'].dt.quarter
    df['year'] = df['date'].dt.year
    df['is_monsoon'] = ((df['week_of_year'] >= 22) & (df['week_of_year'] <= 39)).astype(int)
    return df

def target_encode_categoricals(df):
    """Encode infrastructure features (Tower, Substation, etc) into numerical."""
    logging.info("Target encoding spatial & infrastructure categories...")
    categorical_cols = ['location', 'tower_type', 'substation', 'project_id', 'material']
    
    # We will use simple frequency encoding so LightGBM can process it as floats
    for col in categorical_cols:
        freq = df[col].value_counts(normalize=True)
        df[f'{col}_freq_encoded'] = df[col].map(freq)
        
    # Cast base categoricals as 'category' dtype for native LightGBM support
    for col in categorical_cols:
        df[col] = df[col].astype('category')
        
    return df

def create_lag_features(df, lags=[1, 4, 12, 52]):
    """Create lag features over different periods (1 week, 1 month, 1 quarter, 1 year)."""
    logging.info(f"Generating periodic drawdown lag features for lags {lags} weeks...")
    df = df.sort_values(by=['project_id', 'material', 'date'])
    for lag in lags:
        df[f'quantity_lag_{lag}w'] = df.groupby(['project_id', 'material'])['quantity_demanded'].shift(lag)
    return df

def create_rolling_features(df, windows=[4, 12]):
    """Create rolling mean features to capture supply chain velocity."""
    logging.info(f"Generating running velocity features for windows {windows} weeks...")
    df = df.sort_values(by=['project_id', 'material', 'date'])
    for w in windows:
        df[f'quantity_roll_mean_{w}w'] = df.groupby(['project_id', 'material'])['quantity_demanded'].transform(lambda x: x.rolling(window=w, min_periods=1).mean())
        df[f'budget_roll_mean_{w}w'] = df.groupby(['project_id', 'material'])['budget_allocated_inr'].transform(lambda x: x.rolling(window=w, min_periods=1).mean())
    return df

def feature_engineering(df):
    """Generate financial constraint features."""
    logging.info("Calculating financial risk and overrun features...")
    df['budget_utilization_ratio'] = df['total_cost_inr'] / np.maximum(df['budget_allocated_inr'], 1)
    df['is_over_budget'] = (df['budget_utilization_ratio'] > 1.0).astype(int)
    return df

def clean_data(df):
    """Handle missing values generated by lag/rolling operations."""
    logging.info("Cleaning missing sequence values...")
    
    # Pandas fails to bfill on categorical columns in some versions. Cast to object first.
    cat_cols = df.select_dtypes(include=['category']).columns
    for col in cat_cols:
        df[col] = df[col].astype('object')
        
    # Group by project and material to carefully backfill sequence starts
    df = df.groupby(['project_id', 'material']).apply(lambda group: group.bfill()).reset_index(drop=True)
    df.fillna(0, inplace=True)
    
    return df

def main():
    if not RAW_DATA_PATH.exists():
        logging.error(f"Raw data file {RAW_DATA_PATH} not found. Please run data_ingestion.py first.")
        return

    logging.info(f"Loading raw PowerGrid dataset from {RAW_DATA_PATH}...")
    df = pd.read_csv(RAW_DATA_PATH)
    logging.info(f"Loaded {len(df)} rows.")

    df = extract_time_features(df)
    df = target_encode_categoricals(df)
    df = create_lag_features(df)
    df = create_rolling_features(df)
    df = feature_engineering(df)
    df = clean_data(df)

    # Convert object columns that weren't caught to category
    for col in df.select_dtypes(include=['object']).columns:
        df[col] = df[col].astype('category')

    logging.info(f"Saving processed supply chain features to {PROCESSED_DATA_PATH}...")
    PROCESSED_DATA_PATH.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(PROCESSED_DATA_PATH, index=False)
    logging.info("Preprocessing completed successfully.")

if __name__ == "__main__":
    main()
